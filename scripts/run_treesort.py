#!/usr/bin/env python

import argparse
import csv
from dataclasses import dataclass
from enum import Enum
import json
from math import ceil, floor, fmod, trunc
import os
import re
import subprocess
import sys
import traceback
from typing import Optional

#-----------------------------------------------------------------------------------------------------------------------------
# Define constants
#-----------------------------------------------------------------------------------------------------------------------------

# The BV-BRC URL
BVBRC_URL = "https://www.bv-brc.org"

# The default reference segment.
DEFAULT_REF_SEGMENT = "HA"

# The forester Java code parses the result .tre file and returns strain names and their annotations.
FORESTER_CLASS = "org.forester.application.treesort_reformate"
FORESTER_JAR = "forester.jar"
FORESTER_JAVA_PARAMETERS = "-Xmx8048m"

# The name of the descriptor file.
DESCRIPTOR_FILE_NAME = "descriptor.csv"

# The default name of the input FASTA file.
INPUT_FASTA_FILE_NAME = "input.fasta"

# A CSV file we will create and populate with reassortment data.
REASSORTMENTS_FILE_NAME = "TreeSort_reassortments.csv"

# The name of the result directories created by TreeSort will begin
# with a segment name and end with this suffix.
RESULT_DIRECTORY_SUFFIX = "-input.fasta.aln.treetime"

# The result files created by TreeSort for every segment.
RESULT_FILENAMES = [ "outliers.tsv", "root_to_tip_regression.pdf", "rtt.csv" ]

# The names of the files we use to capture stdout and stderr.
STDOUT_FILENAME = "stdout.txt"
STDERR_FILENAME = "stderr.txt"

# The name of the summary HTML file we will generate.
SUMMARY_FILENAME = "TreeSort_analysis_results.html"

# The name of the HTML template file used when generating the summary file.
SUMMARY_TEMPLATE_FILENAME = "treesort_summary_template.html"

# The file extension of the annotated tree file generated by TreeSort.
TREE_FILE_EXTENSION = ".tre"

# The text output files from TreeTime's stdout start with a segment name and end with this suffix.
TREETIME_STDOUT_FILE_SUFFIX = "-treetime-stdout.txt"

# A list of valid segments for the influenza virus.
VALID_SEGMENTS = ["PB2", "PB1", "PA", "HA", "NP", "NA", "MP", "NS"]


#-----------------------------------------------------------------------------------------------------------------------------
# Enums
#-----------------------------------------------------------------------------------------------------------------------------

# The source of the input FASTA.
class InputSource(str, Enum):

   # FASTA pasted into a textarea on the UI.
   FastaData = "fasta_data"

   # Files generated by a previous run of prepare_treesort_dataset.sh
   FastaExistingDataset = "fasta_existing_dataset"

   # A workspace identifier for the FASTA file.
   FastaFileID = "fasta_file_id"

   # A workspace identifier for a genome group.
   FastaGroupID = "fasta_group_id"
   

class MatchType(str, Enum):
   Default = "default"
   EPI = "epi"
   RegEx = "regex"
   Strain = "strain"


# Reassortment inference methods
class InferenceMethod(str, Enum):
   Local = "local"
   MinCut = "mincut"


# Command-line script flags / optional arguments.
class ScriptOption(str, Enum):
   CladesPath = "--clades"
   DescriptorPath = "-i"
   Deviation = "--dev"
   EqualRates = "--equal-rates"
   FastTree = "--fast"
   MatchOnEPI = "--match-on-epi"
   MatchOnRegex = "--match-on-regex"
   MatchOnStrain = "--match-on-strain"
   Method = "-m"
   NoCollapse = "--no-collapse"
   OutputFilename = "-o"
   PValue = "--pvalue"
   Segments = "--segments"


# The reference segment inference method.
class TreeInference(str, Enum):
   FastTree = "FastTree"
   IQTree = "IQ-Tree"
   # RAxML = "RAxML" # Not implemented yet
 

#-----------------------------------------------------------------------------------------------------------------------------
# Utility functions
#-----------------------------------------------------------------------------------------------------------------------------

# Trim a string that's possibly null and always return a trimmed, non-null value.
def safe_trim(text: Optional[str]):
   if not text:
      return ""
   else:
      return text.strip()


#-----------------------------------------------------------------------------------------------------------------------------
# Classes
#-----------------------------------------------------------------------------------------------------------------------------

# The contents of the jobdesc.json file.
@dataclass
class JobData:
   clades_path: str
   deviation: float
   equal_rates: bool
   inference_method: Optional[InferenceMethod]
   input_fasta_existing_dataset: Optional[str]
   input_fasta_data: Optional[str]
   input_fasta_file_id: Optional[str]
   input_fasta_group_id: Optional[str]
   input_source: InputSource
   match_regex: Optional[str]
   match_type: Optional[MatchType]
   no_collapse: bool
   output_file: str
   output_path: str
   p_value: float
   ref_segment: str
   ref_tree_inference: TreeInference
   segments: Optional[str]


# A collection of result data to include in the analysis HTML file.
class Results:

   # This segment name maintains state when parsing over segment data in stdout.
   current_segment: str|None

   # JSON data that will be deserialized on the TreeSort analysis results page.
   json: str

   # A list of text info for each segment.
   # TODO: Use an enum for the key?
   segment_data: dict[str, list[str]]

   # TreeSort's raw stdout and a list of parsed data.
   treesort_stdout: str
   treesort_list: list[str]

   # C-tor
   def __init__(self):
      self.json = ""
      self.segment_data = {}
      self.treesort_stdout = ""
      self.treesort_list = []


# The class responsible for processing input parameters, preparing the input file, and 
# running the TreeSort application.
class TreeSortRunner:

   # The base URL
   base_url: str

   # Segments found in the input FASTA file.
   fasta_segments: list[str]

   # the name of the directory containing the input FASTA file.
   input_directory: str

   # The name of the FASTA file to use as input. This is specified in job_data.
   input_filename: str

   # The JSON data for the job.
   job_data: JobData

   # Reassortment data generated in parse_annotated_tree.
   reassorted_strains = []

   # A collection of result data to include in the analysis HTML file.
   results: Results

   # The directory where the scripts will be run.
   work_directory: str


   # C-tor
   def __init__(self, input_directory: str, job_data: JobData, work_directory: str):
         
      # The input directory
      self.input_directory = input_directory
      if not self.input_directory or len(self.input_directory) < 1:
         raise ValueError("The input directory parameter is invalid")
      
      # The work directory
      self.work_directory = work_directory
      if not self.work_directory or len(self.work_directory) < 1:
         raise ValueError("The work directory parameter is invalid")
      
      # Initialize member variables.
      self.fasta_segments = []

      # Determine the base URL.
      if "P3_BASE_URL" in os.environ:
         self.base_url = os.environ["P3_BASE_URL"]
      else:
         self.base_url = BVBRC_URL

      # Validate the job data.
      if not job_data:
         raise ValueError("A job data parameter was not provided")
      
      self.job_data = job_data

      # Validate the job data.
      if not TreeSortRunner.is_job_data_valid(self.job_data):
         raise ValueError("Job data in the constructor is invalid")
      
      # Initialize the results object.
      self.results = Results()


   # Create the summary report file.
   def create_summary_html(self) -> bool:

      # The top-level path 
      top = safe_trim(os.getenv("KB_TOP"))
      if len(top) < 1:
         raise Exception("Invalid KB_TOP environment variable in create_summary_html.")
      
      # The path depends on whether TreeSort is run in production or development.
      dev_path = os.path.join(top, "modules", "treesort", "lib", SUMMARY_TEMPLATE_FILENAME)
      prod_path = os.path.join(top, "lib", SUMMARY_TEMPLATE_FILENAME)

      if os.path.exists(prod_path):
         template_path = prod_path
      elif os.path.exists(dev_path):
         template_path = dev_path
      else:
         raise Exception(f"Unable to find {SUMMARY_TEMPLATE_FILENAME}")

      # The HTML template file as a string.
      html_template = None

      try:
         with open(template_path, "r", encoding="utf-8") as file:
            html_template = safe_trim(file.read())
            if len(html_template) < 1:
               raise Exception("Invalid HTML template")
            
      except FileNotFoundError:
         raise Exception(f"Error: The file {template_path} was not found.")
      
      except Exception as e:
         raise Exception(f"An error occurred: {e}")

      # Format the stdout from prepare_treesort_dataset and TreeSort as HTML.
      self.format_results()


      treesort_summary = ""

      if len(self.results.treesort_list) > 0:

         for item in self.results.treesort_list:
            treesort_summary += f"<li>{item}</li>"

         treesort_summary = f"<ul>{treesort_summary}</ul>"

      # The values of the JavaScript variables in the template.
      js_variables = {
         "{{reassortments_filename}}": REASSORTMENTS_FILE_NAME,
         "{{result_filename}}": f"{self.job_data.output_file}{TREE_FILE_EXTENSION}",
         "\"{{results_json}}\"": self.results.json,
         "{{segments}}": self.job_data.segments,
         "{{treesort_summary}}": treesort_summary,
         "{{workspace_folder}}": ""
      }

      # Replace all JavaScript variable strings in the template text.
      for key, value in js_variables.items():
         html_template = html_template.replace(key, value)

      # The summary file will be created in the work directory.
      summary_path = f"{self.work_directory}/{SUMMARY_FILENAME}"

      try:
         # Create the summary HTML file.
         with open(summary_path, "w+") as summary_file:
            summary_file.write(str(html_template))

      except Exception as e:
         raise IOError(f"Error creating the summary file:\n {e}\n")

      return True


   # Format the Results object's data as HTML.
   def format_results(self):

      if not self.results:
         raise Exception("The results object is invalid")
      
      # Parse TreeSort's stdout
      stdout = safe_trim(self.results.treesort_stdout)
      if len(stdout) > 0:
         
         # Iterate over every line from stdout and parse it.
         for line in stdout.splitlines():
            self.parse_treesort_stdout_line(line)

      # Parse the segment-specific output files containing TreeTime's stdout.
      self.process_treetime_stdout_files()


      # Generate JSON for segment_data in the results object.
      segments_json = ""

      # Generate JSON for the segment data.
      for segment in self.results.segment_data.keys():

         # JSON for this segment's data.
         segment_json = ""

         segment_lines = self.results.segment_data[segment]
         if segment_lines and len(segment_lines) > 0:
            
            for line in segment_lines:

               if len(segment_json) > 0:
                  segment_json += ","

               segment_json += f"\"{line}\""

            if len(segments_json) > 0:
               segments_json += ","

            segments_json += f"\"{segment}\":[{segment_json}]"
         
      # Generate a JSON array for the treesort list.
      summary_array = ""
      if self.results.treesort_list:
         for line in self.results.treesort_list:
            if len(summary_array) > 0:
               summary_array += ","
            summary_array += f"\"{line}\""

      # Assemble the components as JSON.
      self.results.json = f"{{\"segments\":{{{segments_json}}}, \"summary\":[{summary_array}]}}"

      # TESTING
      sys.stdout.write(f"\n\n{self.results.json}\n\n")

      
   # Convert the root date formatted as a decimal to a standard MM/DD/YYYY.
   def format_root_date(self, str_decimal: str, year: str):

      """ 
      Here's how TreeSort converts a date into a decimal format:
      
      decimal_date = ((date.month - 1) * 30 + date.day) / 365.0  + date.year
      
      """

      result_date = "invalid"

      if not str_decimal or len(str_decimal) < 1 or not year or len(year) < 1:
         return result_date

      f_decimal = floor((float(str_decimal) * 365.0)+ 0.5)
      
      try:
         # Divide by 365 and "round half up".
         f_decimal = floor((float(str_decimal) * 365.0) + 0.5)
      
         # Calculate the month and make sure it has 2 digits.
         month = str(trunc(f_decimal / 30) + 1)
         if len(month) == 1:
            month = f"0{month}"

         # Calculate the day and make sure it has 2 digits.
         day = str(ceil(fmod(f_decimal, 30)))
         if len(day) == 1:
            day = f"0{day}"

         result_date = f"{month}/{day}/{year}"

      except Exception as e:
         sys.stderr.write(f"Unable to format a date in decimal format:\n {e}\n")
         result_date = "invalid"
      
      return result_date
   

   # Is the JobData instance valid?
   @staticmethod
   def is_job_data_valid(job_data: JobData) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.is_job_data_valid\n")

      try:
         if not job_data or not isinstance(job_data, JobData):
            raise Exception("job_data is empty")
         
         # Inference method
         if job_data.inference_method not in [m.value for m in InferenceMethod]:
            job_data.inference_method = InferenceMethod.Local

         # Validate the job's input_source.
         TreeSortRunner.validate_input_source(job_data) 

         # Match type and match regex
         match_regex = safe_trim(job_data.match_regex)
         if job_data.match_type == MatchType.RegEx and len(match_regex) < 1:
            raise ValueError("The match regular expression was not provided")

         # Validate the output path.
         if not job_data.output_path:
            raise ValueError("The output path is invalid")

         # Validate the output filename
         if not job_data.output_file:
            raise ValueError("The output filename is invalid")
         
         # If output_file has a file extension, remove it (it will be added later, as necessary).
         job_data.output_file = os.path.splitext(job_data.output_file)[0]

         # Validate the reference segment and provide a default if not provided.
         refSegment = safe_trim(job_data.ref_segment)
         if not refSegment:
            refSegment = DEFAULT_REF_SEGMENT

         elif not refSegment in VALID_SEGMENTS:
            raise ValueError(f"Invalid reference segment: {refSegment}")

         # Reference tree inference
         if not job_data.ref_tree_inference:
            job_data.ref_tree_inference = TreeInference.FastTree

         # Validate the segments
         segments = safe_trim(job_data.segments)
         if len(segments) > 0:
            for segment in segments.split(","):
               if not segment.upper() in VALID_SEGMENTS:
                  raise ValueError(f"Invalid segment: {segment}")
         else:
            # TreeSort accepts an empty segments parameter as "all segments", but we are 
            # explicitly populating it here so it can be used when creating the summary file.
            job_data.segments = ",".join(VALID_SEGMENTS)

      except Exception as e:
         sys.stderr.write(f"Invalid job data:\n {e}\n")
         return False

      return True
   

   # Parse the annotated tree file for reassortment info.
   def parse_annotated_tree(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.parse_annotated_tree\n")
      
      # The result status defaults to true.
      result_status = True

      # Initialize the list of results.
      results = []

      # The path of the CSV output file and the annotated tree input file.
      csv_file_path = f"{self.work_directory}/{self.job_data.output_file}.csv"
      tree_file_path = f"{self.work_directory}/{self.job_data.output_file}{TREE_FILE_EXTENSION}"

      # The path of the strain reassortments CSV file we will create.
      reassortments_path = f"{self.work_directory}/{REASSORTMENTS_FILE_NAME}"

      # Get the path for forester.jar.
      # TODO: this is only temporary...forester.jar will be updated in the container soon (?).
      top = safe_trim(os.getenv("KB_TOP"))
      if len(top) < 1:
         raise Exception("Invalid KB_TOP environment variable in parse_annotated_tree.")
   
      # The path depends on whether TreeSort is run in production or development.
      dev_path = os.path.join(top, "modules", "treesort", "lib", FORESTER_JAR)
      prod_path = os.path.join(top, "lib", FORESTER_JAR)

      if os.path.exists(prod_path):
         forester_path = prod_path
      elif os.path.exists(dev_path):
         forester_path = dev_path
      else:
         raise Exception(f"Unable to find {FORESTER_JAR}")

      try:
         cmd = ["java", FORESTER_JAVA_PARAMETERS, "-cp", forester_path, FORESTER_CLASS]

         # Add the path of the annotated tree file.
         cmd.append(tree_file_path)

         # Add the path of the CSV output file.
         cmd.append(csv_file_path)

         # Display the command about to be run.
         print(f"{' '.join(cmd)}\n")

         # Run the command
         cmd_result = subprocess.call(cmd, shell=False)

         if cmd_result > 0 or not os.path.exists(csv_file_path):
            raise Exception(f"Forester was unable to generate the CSV file")
         
         # Open the CSV file
         with open(csv_file_path, newline="", encoding="utf-8") as csvfile:
            reader = csv.reader(csvfile)

            sys.stdout.write("\nReading the results CSV file.\n")

            for row in reader:
               
               is_reassorted = False
               is_uncertain = False

               # Get the strain/isolate name.
               strain = safe_trim(row[0])
               if len(strain) < 1:
                  continue
               
               # Maintain a distance value for each segment.
               PB2 = ""
               PB1 = ""
               PA = ""
               HA = ""
               NP = ""
               NA = ""
               MP = ""
               NS = ""

               reassortment = ""

               # Look for annotations in columns 1 and 2 (column 0 should have the strain name).
               annotation1 = row[1] if len(row) > 1 else None
               annotation2 = row[2] if len(row) > 2 else None

               # Did this strain have reassortment?
               if annotation1 == "is_reassorted=1":
                  # This column should have one or more segment names and distances.
                  if not annotation2:
                     continue
                  reassortment = annotation2
                  is_reassorted = True

               elif annotation2 == "is_reassorted=1":
                  # This column should have one or more segment names and distances.
                  if not annotation1:
                     continue
                  reassortment = annotation1
                  is_reassorted = True

               # If reassortment was detected we will determine the affected segment(s).
               if is_reassorted:

                  # &rea="NA(124)"
                  
                  # Determine which segments were reassorted and get each one's distance.
                  for token in reassortment.replace("rea=", "").strip().split(","):

                     if token.startswith("?"):
                        is_uncertain = True
                        token = token[1:]

                     match = re.match(r"([A-Z0-9]+)\((\d+)\)", token)
                     if match:
                        name, number = match.groups()
                        if name == "PB2":
                           PB2 = number
                        elif name == "PB1":
                           PB1 = number
                        elif name == "PA":
                           PA = number
                        elif name == "HA":
                           HA = number
                        elif name == "NP":
                           NP = number
                        elif name == "NA":
                           NA = number
                        elif name == "MP":
                           MP = number
                        elif name == "NS":
                           NS = number
                  
               # Update the results
               results.append({
                  "strain": strain, 
                  "is_reassorted": "Y" if is_reassorted else "",
                  "is_uncertain": "Y" if is_uncertain else "",
                  "PB2": PB2,
                  "PB1": PB1,
                  "PA": PA,
                  "HA": HA,
                  "NP": NP,
                  "NA": NA,
                  "MP": MP,
                  "NS": NS,
               })

         if len(results) > 0:

            sys.stdout.write(f"Writing transformed reassortment data to {reassortments_path}\n\n")

            # Sort the results so that the reassorted strains are at the top.
            sorted_results = sorted(results, key=lambda r: r["is_reassorted"], reverse=True)

            # Create the strain reassortments file.
            with open(reassortments_path, "w+", newline="", encoding="utf-8") as result_file:
               writer = csv.DictWriter(result_file, fieldnames=["strain", "is_reassorted", "is_uncertain", "PB2", "PB1", "PA", "HA", "NP", "NA", "MP", "NS"])
               writer.writeheader()
               writer.writerows(sorted_results)

         else:
            sys.stderr.write("No strains were found in the CSV results file")

         # TODO: Delete the CSV file created by forester.jar?

      except Exception as e:
         sys.stderr.write(f"Error in TreeSort:\n {e}\n")
         return False
 
      return result_status
   

   # Parse a line from TreeSort's stdout to look for important info.
   def parse_treesort_stdout_line(self, line: str):

      line = safe_trim(line)

      if not line:
         return
      
      # Skip lines that refer to a tmp directory.
      # TODO: Possibly unnecessary.
      if "/tmp/" in line:
         return
   
      # Look for information not specific to a segment.
      if line.endswith(" strains in common across the alignments.") or \
         line.startswith("Multifurcations resolved: "):

         self.results.treesort_list.append(line)
         return

      # Look for segment-specific reassortment events.
      match = re.search(r'Inferred reassortment events with ([A-Za-z0-9]+):\s*(\d+)', line)
      if match:
         segment_name = match.group(1)
         event_count = match.group(2)

         # TODO: Make sure this is a valid segment name.
         current_segment = segment_name

         # Update the segment data dictionary.
         if current_segment not in self.results.segment_data:
            self.results.segment_data[current_segment] = []
         self.results.segment_data[current_segment].append(f"Inferred reassortment events: {event_count}")
         return
      
      match = re.search(r'/Identified exact branches for (\d+)\/\d+ of them/gm', line)
      if match and self.results.current_segment:

         exact_branches = match.group(1)

         current_segment = self.results.current_segment

         if current_segment not in self.results.segment_data:
            self.results.segment_data[current_segment] = []
         self.results.segment_data[current_segment].append(f"Identified exact branches for {exact_branches} of the events")

         # Re-initialize the current segment.
         self.results.current_segment = None

      return
   

   # Parse a line from TreeTime's stdout to look for segment-specific info.
   def parse_treetime_stdout_line(self, line: str, segment_name: str):

      # Root-Tip-Regression info
      
      # Rate
      match = re.search(r"\S*--rate:\s*(\S+)", line)
      if match:
         rate = match.group(1)

         if not segment_name in self.results.segment_data:
            self.results.segment_data[segment_name] = []

         self.results.segment_data[segment_name].append(f"Estimated substitution rate: {rate}")
         return
      
      # R^2
      match = re.search(r'\S*\-\-r\^2:\s*(\d+\.\d+)', line)
      if match:
         r_2 = match.group(1)

         if not segment_name in self.results.segment_data:
            self.results.segment_data[segment_name] = []

         self.results.segment_data[segment_name].append(f"Fraction of variation in root-to-tip distance: {r_2}")
         return
      
      # Root date
      match = re.search(r'\S*\-\-\-\s*root\-date:\s*(\d+\.\d+)', line)
      if match:
         decimal_date = match.group(1)

         root_date = "invalid"

         # Convert the floating point date to a standard format.
         date_match = re.search(r'(\d+).(\d+)', decimal_date)
         if date_match:
            
            year = date_match.group(1)
            decimal_part = date_match.group(2)

            # Convert the root date formatted as a decimal to a standard MM/DD/YYYY.
            root_date = self.format_root_date(decimal_part, year)

            if not segment_name in self.results.segment_data:
               self.results.segment_data[segment_name] = []

            self.results.segment_data[segment_name].append(f"The root date is {root_date}")
            return

      return
   

   # Determine the source of the FASTA input file and prepare it for use.
   def prepare_input_file(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.prepare_input_file\n")

      try:
         # The input source determines how the input file is provided.
         input_source = safe_trim(self.job_data.input_source)

         if input_source == InputSource.FastaFileID.value:

            # Populate the input filename, including its full path.
            self.input_filename = f"{self.input_directory}/{INPUT_FASTA_FILE_NAME}"

            try:
               # Copy the input file from the workspace to the working directory.
               fetch_fasta_cmd = ["p3-cp", f"ws:{self.job_data.input_fasta_file_id}", self.input_filename]
               subprocess.call(fetch_fasta_cmd, shell=False)

            except Exception as e:
               raise IOError("Error copying FASTA file from workspace:\n %s" % str(e))

         elif input_source == InputSource.FastaGroupID.value:

            # TODO: Figure out the best way to handle this scenario.
            raise ValueError("Processing a genome group is not yet implemented")

         elif input_source == InputSource.FastaExistingDataset:

            # TODO: Figure out the best way to handle this scenario.
            raise ValueError("Processing an existing dataset is not yet implemented")

         elif input_source == InputSource.FastaData.value:
      
            # Create the input filename, including its full path.
            self.input_filename = f"{self.input_directory}/{INPUT_FASTA_FILE_NAME}"

            try:
               # Create a file that contains the input FASTA data.
               with open(self.input_filename, "w+") as input_file:
                  input_file.write(str(self.job_data.input_fasta_data))

            except Exception as e:
               raise IOError(f"Error copying FASTA data to input file:\n {e}\n")

         else:
            raise ValueError(f"Invalid input source: {input_source}")

         # Validate the input filename.
         if not self.input_filename:
            raise ValueError("Invalid input filename (empty)")
         
         # Validate the input FASTA file.
         if not os.path.exists(self.input_filename) or os.path.getsize(self.input_filename) == 0:
            raise IOError("Input FASTA file is invalid or empty")
  
         # TODO: This is a good place to validate the input FASTA file. Currently, the 
         # FASTA header requires the segment name/abbreviation surrounded by |'s and a date at the end.

      except Exception as e:
         sys.stderr.write(f"Error processing input file:\n {e}\n")
         return False
      
      return True


   # Parse the segment-specific output files containing TreeTime's stdout.
   def process_treetime_stdout_files(self):

      segments = safe_trim(self.job_data.segments)
      if len(segments) < 1:
         sys.stderr.write("No segments were found in process_treetime_stdout_files")
         return

      # Iterate over all segments
      for segment in segments.split(","):

         segment = safe_trim(segment)

         output_filename = f"{self.work_directory}/{segment}{TREETIME_STDOUT_FILE_SUFFIX}"
   
         try:
            # Open the segment-specific output file.
            with open(output_filename, "r", encoding="utf-8") as output_file:

               lines = output_file.readlines()

               # The first line should contain the segment name.
               segment_name = safe_trim(lines[0])
               if segment_name.startswith("SEGMENT: "):
                  segment_name = segment_name.replace("SEGMENT: ", "")

               # Iterate over every line after the first line.
               for line in lines[1:]:

                  # Parse a line from TreeTime-root's stdout.
                  self.parse_treetime_stdout_line(line, segment_name)

         except FileNotFoundError:
            continue

      return


   # Run prepare_dataset.sh to build alignments and trees and compile a descriptor file.
   def run_prepare_dataset(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.run_prepare_dataset\n")
      
      # The result status defaults to false.
      result_status = False

      try:
         cmd = ["prepare_treesort_dataset"]

         # Specify the reference tree inference method.
         # TODO: Consider supporting RAxML in addition to FastTree and IQ-Tree. 
         if (self.job_data.ref_tree_inference and self.job_data.ref_tree_inference == TreeInference.FastTree.value):
            cmd.append(ScriptOption.FastTree.value)

         # The segments (optional)
         if self.job_data.segments:
            cmd.append(ScriptOption.Segments.value)
            cmd.append(self.job_data.segments)

         # The input FASTA file
         cmd.append(self.input_filename)

         # The reference segment
         refSegment = self.job_data.ref_segment
         if refSegment:
            cmd.append(refSegment)

         # The working directory
         cmd.append(self.work_directory)

         # Display the command about to be run.
         print(f"{' '.join(cmd)}\n")

         result = subprocess.run(cmd, shell=False, capture_output=True, text=True)
         if result.returncode == 0:
            
            result_status = True

            # Iterate over lines in the result's stdout to 1) look for the segments 
            # that were found, 2) parse TreeTime data by segment, and 3) to echo messages 
            # to stdout.
            for line in result.stdout.strip().splitlines():

               if line.startswith("FOUND_SEGMENTS:"):
                  self.job_data.segments = line.replace("FOUND_SEGMENTS:", "").strip()

                  print(f"job_data.segments has been updated to {self.job_data.segments}")

               else:
                  # Write the script's stdout to run_treesort.py's stdout.
                  sys.stdout.write(f"{line}\n")

      except Exception as e:
         sys.stderr.write(f"Error preparing dataset:\n {e}\n")
         return False
         
      return result_status


   # Run TreeSort in a sub-process.
   def tree_sort(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.tree_sort\n")
      
      # The result status defaults to false.
      result_status = False

      try:
         cmd = ["treesort"]

         # The clades output path
         clades_path = safe_trim(self.job_data.clades_path)
         if len(clades_path) > 0:
            cmd.append(ScriptOption.CladesPath.value)
            cmd.append(clades_path)

         # The descriptor file is in the working directory.
         cmd.append(ScriptOption.DescriptorPath.value)
         cmd.append(f"{self.work_directory}/{DESCRIPTOR_FILE_NAME}")

         #-----------------------------------------------------------------------------------------------------------------------------
         # The "match on" options are mutually exclusive.
         #-----------------------------------------------------------------------------------------------------------------------------
         if self.job_data.match_type == MatchType.Strain:
            cmd.append(ScriptOption.MatchOnStrain.value)

         elif self.job_data.match_type == MatchType.EPI:
            cmd.append(ScriptOption.MatchOnEPI.value)

         elif self.job_data.match_type == MatchType.RegEx and self.job_data.match_regex:
            cmd.append(ScriptOption.MatchOnRegex.value)
            cmd.append(self.job_data.match_regex)

         # No collapse
         if self.job_data.no_collapse:
            cmd.append(ScriptOption.NoCollapse.value)

         # The name of the output file to create in the work directory. 
         cmd.append(ScriptOption.OutputFilename.value)
         cmd.append(f"{self.work_directory}/{self.job_data.output_file}{TREE_FILE_EXTENSION}")
         
         # Equal rates
         if self.job_data.equal_rates:
            cmd.append(ScriptOption.EqualRates.value)

         # Print the treesort command line that will be run.
         print(f"{' '.join(cmd)}\n")

         # Run the command
         result = subprocess.run(cmd, capture_output=True, text=True)

         # Update the results object with TreeSort's stdout.
         self.results.treesort_stdout = result.stdout

         if result.returncode == 0:
            result_status = True
                  
      except Exception as e:
         sys.stderr.write(f"Error in TreeSort:\n {type(e).__name__}: {e}\n")
         return False
      
      return result_status


   # Validate the job's input_source.
   @staticmethod
   def validate_input_source(job_data: JobData) -> bool:

      if job_data.input_source not in [i.value for i in InputSource]:
         raise ValueError("job_data.input_source is not a valid input source") 

      if job_data.input_source == InputSource.FastaFileID.value:

         # Make sure an input_fasta_file_id value was provided.
         if not job_data.input_fasta_file_id:
            raise ValueError("The input FASTA file ID is invalid")
         
         elif job_data.input_fasta_file_id.startswith("ws:"):

            # Remove the "ws:" prefix from the directory name.
            job_data.input_fasta_file_id = job_data.input_fasta_file_id[3:]
      else:
         raise ValueError("The input source is invalid")
      
      return True
   

def main(argv=None) -> bool:
    
   # Exclude the script name.
   if argv is None:
      argv = sys.argv[1:]  

   # Create an argument parser.
   parser = argparse.ArgumentParser(description="A script to run TreeSort")
   parser.add_argument("-i", "--input-directory", dest="input_directory", help="The directory with FASTA input file(s)", required=True)
   parser.add_argument("-j", "--job-filename", dest="job_filename", help="The job description JSON file", required=True)
   parser.add_argument("-w", "--work-directory", dest="work_directory", help="The directory where intermediate files are generated", required=True)
   
   args = parser.parse_args()

   # The input directory parameter.
   input_directory = safe_trim(args.input_directory)
   if len(input_directory) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid input directory parameter\n")
      sys.exit(-1)

   # The job filename parameter.
   job_filename = safe_trim(args.job_filename)
   if len(job_filename) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid job filename parameter\n")
      sys.exit(-1)

   # The work directory parameter.
   work_directory = safe_trim(args.work_directory)
   if len(work_directory) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid work directory parameter\n")
      sys.exit(-1)

   job_data = None

   try:
      # Load job data from the JSON file.
      with open(job_filename, "r", encoding="utf-8") as job_file:
         job_dict = json.load(job_file)
         job_data = JobData(**job_dict)

   except Exception as e:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write(f"Invalid job file:\n{e}\n")
      sys.exit(-1)

   try:
      # Create a TreeSortRunner instance
      runner = TreeSortRunner(input_directory, job_data, work_directory)

   except Exception as e:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write(f"Unable to create an instance of TreeSortRunner:\n{e}\n")
      sys.exit(-1)
   
   # Prepare the input file
   if not runner.prepare_input_file():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.prepare_input_file\n")
      sys.exit(-1)

   # Prepare the dataset
   if not runner.run_prepare_dataset():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.run_prepare_dataset\n")
      sys.exit(-1)

   # Run TreeSort
   if not runner.tree_sort():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.tree_sort\n")
      sys.exit(-1)

   # Parse the annotated tree file for reassorted strains.
   runner.parse_annotated_tree()

   # Create a summary HTML file.
   if not runner.create_summary_html():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred TreeSortRunner.create_summary_html\n")
      sys.exit(-1)

   return True


if __name__ == "__main__" :
   result = main()
   if result:
      sys.exit(0)
   else:
      sys.exit(1)
   
