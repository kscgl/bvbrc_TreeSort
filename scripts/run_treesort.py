#!/usr/bin/env python

import argparse
from dataclasses import dataclass
from enum import Enum
import json
import os
import re
import subprocess
import sys
import traceback
from typing import Optional

#-----------------------------------------------------------------------------------------------------------------------------
# Define constants
#-----------------------------------------------------------------------------------------------------------------------------

# The BV-BRC URL
BVBRC_URL = "https://www.bv-brc.org"

# The default reference segment.
DEFAULT_REF_SEGMENT = "HA"

# The name of the descriptor file.
DESCRIPTOR_FILE_NAME = "descriptor.csv"

# The default name of the input FASTA file.
INPUT_FASTA_FILE_NAME = "input.fasta"

# Characters to remove from FASTA headers.
#INVALID_FASTA_CHARS = "[\\['\"(),;:\\]]"

# The name of the result directories created by TreeSort will begin
# with a segment name and end with this suffix.
RESULT_DIRECTORY_SUFFIX = "-input.fasta.aln.treetime"

# The result files created by TreeSort for every segment.
RESULT_FILENAMES = [ "outliers.tsv", "root_to_tip_regression.pdf", "rtt.csv" ]

# The name of the summary HTML file we will generate.
SUMMARY_FILENAME = "TreeSort_analysis_results.html"

# The name of the HTML template file used when generating the summary file.
SUMMARY_TEMPLATE_FILENAME = "treesort_summary_template.html"

# The file extension of the annotated tree file generated by TreeSort.
TREE_FILE_EXTENSION = ".tre"

# A list of valid segments for the influenza virus.
VALID_SEGMENTS = ["PB2", "PB1", "PA", "HA", "NP", "NA", "MP", "NS"]


#-----------------------------------------------------------------------------------------------------------------------------
# Enums
#-----------------------------------------------------------------------------------------------------------------------------

# The source of the input FASTA.
class InputSource(str, Enum):

   # FASTA pasted into a textarea on the UI.
   FastaData = "fasta_data"

   # Files generated by a previous run of prepare_treesort_dataset.sh
   FastaExistingDataset = "fasta_existing_dataset"

   # A workspace identifier for the FASTA file.
   FastaFileID = "fasta_file_id"

   # A workspace identifier for a genome group.
   FastaGroupID = "fasta_group_id"
   

class MatchType(str, Enum):
   Default = "default"
   EPI = "epi"
   RegEx = "regex"
   Strain = "strain"


# Reassortment inference methods
class InferenceMethod(str, Enum):
   Local = "local"
   MinCut = "mincut"


# Command-line script flags / optional arguments.
class ScriptOption(str, Enum):
   CladesPath = "--clades"
   DescriptorPath = "-i"
   Deviation = "--dev"
   EqualRates = "--equal-rates"
   FastTree = "--fast"
   MatchOnEPI = "--match-on-epi"
   MatchOnRegex = "--match-on-regex"
   MatchOnStrain = "--match-on-strain"
   Method = "-m"
   NoCollapse = "--no-collapse"
   OutputFilename = "-o"
   PValue = "--pvalue"
   Segments = "--segments"


# The reference segment inference method.
class TreeInference(str, Enum):
   FastTree = "FastTree"
   IQTree = "IQ-Tree"
   # RAxML = "RAxML" # Not implemented yet
 

#-----------------------------------------------------------------------------------------------------------------------------
# Utility functions
#-----------------------------------------------------------------------------------------------------------------------------

# Trim a string that's possibly null and always return a trimmed, non-null value.
def safeTrim(text: Optional[str]):
   if not text:
      return ""
   else:
      return text.strip()


#-----------------------------------------------------------------------------------------------------------------------------
# Classes
#-----------------------------------------------------------------------------------------------------------------------------

# The contents of the jobdesc.json file.
@dataclass
class JobData:
   clades_path: str
   deviation: float
   equal_rates: bool
   inference_method: Optional[InferenceMethod]
   input_fasta_existing_dataset: Optional[str]
   input_fasta_data: Optional[str]
   input_fasta_file_id: Optional[str]
   input_fasta_group_id: Optional[str]
   input_source: InputSource
   match_regex: Optional[str]
   match_type: Optional[MatchType]
   no_collapse: bool
   output_file: str
   output_path: str
   p_value: float
   ref_segment: str
   ref_tree_inference: TreeInference
   segments: Optional[str]
    

# The class responsible for processing input parameters, preparing the input file, and 
# running the TreeSort application.
class TreeSortRunner:

   # The base URL
   base_url: str

   # Segments found in the input FASTA file.
   fasta_segments: list[str]

   # the name of the directory containing the input FASTA file.
   input_directory: str

   # The name of the FASTA file to use as input. This is specified in job_data.
   input_filename: str

   # The JSON data for the job.
   job_data: JobData

   # The directory where the scripts will be run.
   work_directory: str


   # C-tor
   def __init__(self, input_directory: str, job_data: JobData, work_directory: str):
         
      # The input directory
      self.input_directory = input_directory
      if not self.input_directory or len(self.input_directory) < 1:
         raise ValueError("The input directory parameter is invalid")
      
      # The work directory
      self.work_directory = work_directory
      if not self.work_directory or len(self.work_directory) < 1:
         raise ValueError("The work directory parameter is invalid")
      
      # Initialize member variables.
      self.fasta_segments = []

      # Determine the base URL.
      if "P3_BASE_URL" in os.environ:
         self.base_url = os.environ["P3_BASE_URL"]
      else:
         self.base_url = BVBRC_URL

      # Validate the job data.
      if not job_data:
         raise ValueError("A job data parameter was not provided")
      
      self.job_data = job_data

      # Validate the job data.
      if not self.is_job_data_valid():
         raise ValueError("Job data in the constructor is invalid")
      

   # Create the summary report file.
   def create_summary_html(self) -> bool:

      top = safeTrim(os.getenv("KB_TOP"))
      if len(top) < 1:
         raise Exception("Invalid KB_TOP environment variable in create_summary_html.")
      
      # The path depends on whether TreeSort is run in production or development.
      dev_path = os.path.join(top, "modules", "treesort", "lib", SUMMARY_TEMPLATE_FILENAME)
      prod_path = os.path.join(top, "lib", SUMMARY_TEMPLATE_FILENAME)

      if os.path.exists(prod_path):
         template_path = prod_path
      elif os.path.exists(dev_path):
         template_path = dev_path
      else:
         raise Exception(f"Unable to find {SUMMARY_TEMPLATE_FILENAME}")

      # The HTML template file as a string.
      html_template = None

      try:
         with open(template_path, "r", encoding="utf-8") as file:
            html_template = safeTrim(file.read())
            if len(html_template) < 1:
               raise Exception("Invalid HTML template")
            
      except FileNotFoundError:
         raise Exception(f"Error: The file {template_path} was not found.")
      
      except Exception as e:
         raise Exception(f"An error occurred: {e}")

      # The values of the JavaScript variables in the template.
      js_variables = {
         "{{result_filename}}": f"{self.job_data.output_file}{TREE_FILE_EXTENSION}",
         "{{segments}}": self.job_data.segments,
         "{{workspace_folder}}": "" # f"/workspace/{self.job_data.output_path}/.{self.job_data.output_file}",
      }

      # Replace all JavaScript variable strings in the template text.
      for key, value in js_variables.items():
         html_template = html_template.replace(key, value)

      # The summary file will be created in the work directory.
      summary_path = f"{self.work_directory}/{SUMMARY_FILENAME}"

      try:
         # Create the summary HTML file.
         with open(summary_path, "w+") as summary_file:
            summary_file.write(str(html_template))

      except Exception as e:
         raise IOError(f"Error creating the summary file:\n {e}\n")

      return True


   # Is the JobData instance valid?
   def is_job_data_valid(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.is_job_data_valid\n\n")

      try:
         if not self.job_data or not isinstance(self.job_data, JobData):
            raise Exception("job_data is empty")
         
         # Inference method
         if self.job_data.inference_method not in [m.value for m in InferenceMethod]:
            self.job_data.inference_method = InferenceMethod.Local

         # Validate the job's input_source.
         self.validate_input_source() 

         # Match type and match regex
         match_regex = safeTrim(self.job_data.match_regex)
         if self.job_data.match_type == MatchType.RegEx and len(match_regex) < 1:
            raise ValueError("The match regular expression was not provided")

         # Validate the output path.
         if not self.job_data.output_path:
            raise ValueError("The output path is invalid")

         # Validate the output filename
         if not self.job_data.output_file:
            raise ValueError("The output filename is invalid")
         
         # If output_file has a file extension, remove it (it will be added later, as necessary).
         self.job_data.output_file = os.path.splitext(self.job_data.output_file)[0]

         # Validate the reference segment and provide a default if not provided.
         refSegment = safeTrim(self.job_data.ref_segment)
         if not refSegment:
            refSegment = DEFAULT_REF_SEGMENT

         elif not refSegment in VALID_SEGMENTS:
            raise ValueError(f"Invalid reference segment: {refSegment}")

         # Reference tree inference
         if not self.job_data.ref_tree_inference:
            self.job_data.ref_tree_inference = TreeInference.FastTree

         # Validate the segments
         segments = safeTrim(self.job_data.segments)
         if len(segments) > 0:
            for segment in segments.split(","):
               if not segment.upper() in VALID_SEGMENTS:
                  raise ValueError(f"Invalid segment: {segment}")
         else:
            # TreeSort accepts an empty segments parameter as "all segments", but we are 
            # explicitly populating it here so it can be used when creating the summary file.
            self.job_data.segments = ",".join(VALID_SEGMENTS)

      except Exception as e:
         sys.stderr.write(f"Invalid job data:\n {e}\n")
         return False

      return True
   

   # Determine the source of the FASTA input file and prepare it for use.
   def prepare_input_file(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.prepare_input_file\n\n")

      try:
         # The input source determines how the input file is provided.
         input_source = safeTrim(self.job_data.input_source)

         if input_source == InputSource.FastaFileID.value:

            # Populate the input filename, including its full path.
            self.input_filename = f"{self.input_directory}/{INPUT_FASTA_FILE_NAME}"

            try:
               # Copy the input file from the workspace to the working directory.
               fetch_fasta_cmd = ["p3-cp", f"ws:{self.job_data.input_fasta_file_id}", self.input_filename]
               subprocess.call(fetch_fasta_cmd, shell=False)

            except Exception as e:
               raise IOError("Error copying FASTA file from workspace:\n %s" % str(e))

         elif input_source == InputSource.FastaGroupID.value:

            # TODO: Figure out the best way to handle this scenario.
            raise ValueError("Processing a genome group is not yet implemented")

         elif input_source == InputSource.FastaExistingDataset:

            # TODO: Figure out the best way to handle this scenario.
            raise ValueError("Processing an existing dataset is not yet implemented")

         elif input_source == InputSource.FastaData.value:
      
            # Create the input filename, including its full path.
            self.input_filename = f"{self.input_directory}/{INPUT_FASTA_FILE_NAME}"

            try:
               # Create a file that contains the input FASTA data.
               with open(self.input_filename, "w+") as input_file:
                  input_file.write(str(self.job_data.input_fasta_data))

            except Exception as e:
               raise IOError(f"Error copying FASTA data to input file:\n {e}\n")

         else:
            raise ValueError(f"Invalid input source: {input_source}")

         # Validate the input filename.
         if not self.input_filename:
            raise ValueError("Invalid input filename (empty)")
         
         # Validate the input FASTA file.
         if not os.path.exists(self.input_filename) or os.path.getsize(self.input_filename) == 0:
            raise IOError("Input FASTA file is invalid or empty")
  
         # TODO: This is a good place to validate the input FASTA file. Currently, the 
         # FASTA header requires the segment name/abbreviation surrounded by |'s and a date at the end.

      except Exception as e:
         sys.stderr.write(f"Error processing input file:\n {e}\n")
         return False
      
      return True


   # Run prepare_dataset.sh to build alignments and trees and compile a descriptor file.
   def run_prepare_dataset(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.run_prepare_dataset\n\n")
      
      # The result status defaults to false.
      result_status = False

      try:
         cmd = ["prepare_treesort_dataset"]

         # Specify the reference tree inference method.
         # TODO: Consider supporting RAxML in addition to FastTree and IQ-Tree. 
         if (self.job_data.ref_tree_inference and self.job_data.ref_tree_inference == TreeInference.FastTree.value):
            cmd.append(ScriptOption.FastTree.value)

         # The segments (optional)
         if self.job_data.segments:
            cmd.append(ScriptOption.Segments.value)
            cmd.append(self.job_data.segments)

         # The input FASTA file
         cmd.append(self.input_filename)

         # The reference segment
         refSegment = self.job_data.ref_segment
         if refSegment:
            cmd.append(refSegment)

         # The working directory
         cmd.append(self.work_directory)

         # Display the command about to be run.
         print(f"{' '.join(cmd)}\n\n")

         result = subprocess.run(cmd, shell=False, capture_output=True, text=True)
         if result.returncode == 0:
            
            result_status = True

            # Iterate over the lines in the result's stdout to 1) look for the segments 
            # that were found, and 2) to echo messages to stdout.
            for line in result.stdout.strip().splitlines():
               if line.startswith("FOUND_SEGMENTS:"):
                  self.job_data.segments = line.replace("FOUND_SEGMENTS:", "").strip()

                  print(f"segments has been updated to {self.job_data.segments}")

               else:
                  # Write the script's stdout to run_treesort.py's stdout.
                  sys.stdout.write(f"{line}\n")

      except ValueError as e:
         sys.stderr.write(f"Error preparing dataset:\n {e}\n")
         return False
         
      return result_status


   # Run TreeSort in a sub-process.
   def tree_sort(self) -> bool:

      sys.stdout.write("\nIn TreeSortRunner.tree_sort\n\n")
      
      # The result status defaults to false.
      result_status = False

      try:
         cmd = ["treesort"]

         # The clades output path
         clades_path = safeTrim(self.job_data.clades_path)
         if len(clades_path) > 0:
            cmd.append(ScriptOption.CladesPath.value)
            cmd.append(clades_path)

         # The descriptor file is in the working directory.
         cmd.append(ScriptOption.DescriptorPath.value)
         cmd.append(f"{self.work_directory}/{DESCRIPTOR_FILE_NAME}")

         #-----------------------------------------------------------------------------------------------------------------------------
         # The "match on" options are mutually exclusive.
         #-----------------------------------------------------------------------------------------------------------------------------
         if self.job_data.match_type == MatchType.Strain:
            cmd.append(ScriptOption.MatchOnStrain.value)

         elif self.job_data.match_type == MatchType.EPI:
            cmd.append(ScriptOption.MatchOnEPI.value)

         elif self.job_data.match_type == MatchType.RegEx and self.job_data.match_regex:
            cmd.append(ScriptOption.MatchOnRegex.value)
            cmd.append(self.job_data.match_regex)

         # No collapse
         if self.job_data.no_collapse:
            cmd.append(ScriptOption.NoCollapse.value)

         # The name of the output file to create in the work directory. 
         cmd.append(ScriptOption.OutputFilename.value)
         cmd.append(f"{self.work_directory}/{self.job_data.output_file}{TREE_FILE_EXTENSION}")
         
         # Equal rates
         if self.job_data.equal_rates:
            cmd.append(ScriptOption.EqualRates.value)

         # Print the treesort command line that will be run.
         print(f"{' '.join(cmd)}\n\n")

         # Run the command
         result = subprocess.call(cmd, shell=False)
         if result == 0:
            result_status = True

      except ValueError as e:
         sys.stderr.write(f"Error in TreeSort:\n {e}\n")
         return False
         
      return result_status


   # Validate the job's input_source.
   def validate_input_source(self) -> bool:

      if self.job_data.input_source not in [i.value for i in InputSource]:
         raise ValueError("job_data.input_source is not a valid input source") 

      if self.job_data.input_source == InputSource.FastaFileID.value:

         # Make sure an input_fasta_file_id value was provided.
         if not self.job_data.input_fasta_file_id:
            raise ValueError("The input FASTA file ID is invalid")
         
         elif self.job_data.input_fasta_file_id.startswith("ws:"):

            # Remove the "ws:" prefix from the directory name.
            self.job_data.input_fasta_file_id = self.job_data.input_fasta_file_id[3:]
      else:
         raise ValueError("The input source is invalid")
      
      """
      TODO: The following code might be used in a future release.

      elif self.job_data.input_source == InputSource.FastaGroupID:

         # Make sure an input_fasta_group_id value was provided.
         if not self.job_data.input_fasta_group_id:
            raise ValueError("The input FASTA group ID is invalid")
         
         elif self.job_data.input_fasta_group_id.startswith("ws:"):

            # Remove the "ws:" prefix from the directory name.
            self.job_data.input_fasta_group_id = self.job_data.input_fasta_group_id[3:]

         # TODO: Figure out the best way to handle this.
         raise ValueError("Processing genome groups is not yet supported")
      
      elif self.job_data.input_source == InputSource.FastaExistingDataset:

         # If input_source is an existing dataset, make sure an input_fasta_existing_dataset value was provided.
         if self.job_data.input_source != InputSource.FastaExistingDataset.value:
            raise ValueError(f"The input source {self.job_data.input_source} is invalid")
         
         if not self.job_data.input_fasta_existing_dataset:
            raise ValueError("A directory with an existing dataset is required")
         
         if self.job_data.input_fasta_existing_dataset.startswith("ws:"):

            # Remove the "ws:" prefix from the directory name.
            self.job_data.input_fasta_existing_dataset = self.job_data.input_fasta_existing_dataset[3:]

         # TODO: Figure out the best way to handle this.
         raise ValueError("Processing an existing dataset is not yet supported")
      
      elif self.job_data.input_source == InputSource.FastaData.value:

         # Make sure an input_fasta_data value was provided.
         if not self.job_data.input_fasta_data:
            raise ValueError("The input FASTA data is invalid")
      """

      return True
   

def main(argv=None) -> bool:
    
   # Exclude the script name.
   if argv is None:
      argv = sys.argv[1:]  

   # Create an argument parser.
   parser = argparse.ArgumentParser(description="A script to run TreeSort")
   parser.add_argument("-i", "--input-directory", dest="input_directory", help="The directory with FASTA input file(s)", required=True)
   parser.add_argument("-j", "--job-filename", dest="job_filename", help="The job description JSON file", required=True)
   parser.add_argument("-w", "--work-directory", dest="work_directory", help="The directory where intermediate files are generated", required=True)
   
   args = parser.parse_args()

   # The input directory parameter.
   input_directory = safeTrim(args.input_directory)
   if len(input_directory) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid input directory parameter\n")
      sys.exit(-1)

   # The job filename parameter.
   job_filename = safeTrim(args.job_filename)
   if len(job_filename) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid job filename parameter\n")
      sys.exit(-1)

   # The work directory parameter.
   work_directory = safeTrim(args.work_directory)
   if len(work_directory) == 0:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("Invalid work directory parameter\n")
      sys.exit(-1)

   job_data = None

   try:
      # Load job data from the JSON file.
      with open(job_filename, "r", encoding="utf-8") as job_file:
         job_dict = json.load(job_file)
         job_data = JobData(**job_dict)

   except Exception as e:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write(f"Invalid job file:\n{e}\n")
      sys.exit(-1)

   try:
      # Create a TreeSortRunner instance
      runner = TreeSortRunner(input_directory, job_data, work_directory)

   except Exception as e:
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write(f"Unable to create an instance of TreeSortRunner:\n{e}\n")
      sys.exit(-1)
   
   # Prepare the input file
   if not runner.prepare_input_file():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.prepare_input_file\n")
      sys.exit(-1)

   # Prepare the dataset
   if not runner.run_prepare_dataset():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.run_prepare_dataset\n")
      sys.exit(-1)

   # Run TreeSort
   if not runner.tree_sort():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred in TreeSortRunner.tree_sort\n")
      sys.exit(-1)

   # Create a summary HTML file.
   if not runner.create_summary_html():
      traceback.print_exc(file=sys.stderr)
      sys.stderr.write("An error occurred TreeSortRunner.create_summary_html\n")
      sys.exit(-1)

   return True


if __name__ == "__main__" :
   result = main()
   if result:
      sys.exit(0)
   else:
      sys.exit(1)
   
